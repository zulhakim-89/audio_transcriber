{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPHfbTWsDKEY",
        "outputId": "fe0de5d7-9cfd-4e28-e60c-46d690664c8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get -y install ffmpeg\n",
        "\n",
        "!pip install -q \\\n",
        "  openai \\\n",
        "  pydub \\\n",
        "  ffmpeg-python \\\n",
        "  numpy \\\n",
        "  pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R9sxJAtDaLD",
        "outputId": "c7e573e6-e5f3-4c87-90a2-a44a9b8329e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('/content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+'),\n",
              " PosixPath('/content/drive/MyDrive/whisdiar_gpt4o_smart_ts/wav_16k'),\n",
              " PosixPath('/content/drive/MyDrive/whisdiar_gpt4o_smart_ts/txt'),\n",
              " PosixPath('/content/drive/MyDrive/whisdiar_gpt4o_smart_ts/srt'))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from datetime import timedelta\n",
        "\n",
        "from google.colab import drive, userdata\n",
        "from pydub import AudioSegment\n",
        "from openai import OpenAI\n",
        "\n",
        "# Load API key from Colab secret named: openai-transcribe-key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"openai-transcribe-key\")\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --------- INPUT: folder with .MTS files ----------\n",
        "AUDIO_DIR = Path(\n",
        "    \"/content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+\"\n",
        ")\n",
        "\n",
        "# --------- OUTPUT ROOT ----------\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/whisdiar_gpt4o_smart_ts\")\n",
        "OUT_WAV_DIR  = PROJECT_ROOT / \"wav_16k\"\n",
        "OUT_TXT_DIR  = PROJECT_ROOT / \"txt\"\n",
        "OUT_SRT_DIR  = PROJECT_ROOT / \"srt\"\n",
        "\n",
        "for d in [PROJECT_ROOT, OUT_WAV_DIR, OUT_TXT_DIR, OUT_SRT_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --------- GLOBAL CONFIG ----------\n",
        "SAMPLE_RATE          = 16000\n",
        "AUDIO_BITRATE        = \"24k\"          # compressed speech\n",
        "TRANSCRIBE_MODEL     = \"gpt-4o-transcribe\"\n",
        "SEGMENT_MODEL        = \"gpt-4o\"\n",
        "ENABLE_SPEAKER_GUESS = False          # set True to ask GPT to guess speakers\n",
        "\n",
        "AUDIO_DIR, OUT_WAV_DIR, OUT_TXT_DIR, OUT_SRT_DIR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUrkokCqDcVM"
      },
      "outputs": [],
      "source": [
        "def mts_to_wav_16k_mono(src_path: Path, dst_path: Path) -> Path:\n",
        "    \"\"\"\n",
        "    Convert .MTS (or any media) to 16kHz mono WAV with low bitrate.\n",
        "    \"\"\"\n",
        "    dst_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    cmd = [\n",
        "        \"ffmpeg\",\n",
        "        \"-y\",\n",
        "        \"-i\", str(src_path),\n",
        "        \"-ac\", \"1\",                  # mono\n",
        "        \"-ar\", str(SAMPLE_RATE),     # 16 kHz\n",
        "        \"-b:a\", AUDIO_BITRATE,       # compressed for speed\n",
        "        \"-vn\",\n",
        "        str(dst_path),\n",
        "    ]\n",
        "    subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    return dst_path\n",
        "\n",
        "\n",
        "def normalize_wav(path: Path, target_dBFS: float = -21.0) -> Path:\n",
        "    \"\"\"\n",
        "    Loudness normalization to target_dBFS.\n",
        "    Slightly louder (-21 dBFS) to help Tamil + soft speech.\n",
        "    \"\"\"\n",
        "    audio = AudioSegment.from_file(path)\n",
        "    change_dBFS = target_dBFS - audio.dBFS\n",
        "    normalized = audio.apply_gain(change_dBFS)\n",
        "    normalized.export(path, format=\"wav\")\n",
        "    return path\n",
        "\n",
        "\n",
        "def get_audio_duration_seconds(path: Path) -> float:\n",
        "    audio = AudioSegment.from_file(path)\n",
        "    return len(audio) / 1000.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dzihh2kODhj0"
      },
      "outputs": [],
      "source": [
        "def transcribe_with_gpt4o_transcribe(wav_path: Path, language: str = None, prompt: str = None) -> str:\n",
        "    \"\"\"\n",
        "    One-shot transcription with GPT-4o Transcribe.\n",
        "    Returns full text, no timestamps.\n",
        "    \"\"\"\n",
        "    print(\"Sending audio to GPT-4o Transcribe...\")\n",
        "    with open(wav_path, \"rb\") as f:\n",
        "        tr = client.audio.transcriptions.create(\n",
        "            model=TRANSCRIBE_MODEL,\n",
        "            file=f,\n",
        "            response_format=\"text\",   # full text string\n",
        "            language=language,        # None = auto-detect (needed for Tamil mix)\n",
        "            prompt=prompt,            # Optional prompt to guide the model\n",
        "        )\n",
        "    print(\"Transcription finished.\")\n",
        "    # For response_format=\"text\" the SDK already returns a plain string\n",
        "    if isinstance(tr, str):\n",
        "        return tr\n",
        "    return tr.text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1fPIvqwDj5_"
      },
      "outputs": [],
      "source": [
        "def gpt_smart_segments(full_text: str, total_duration_sec: float, approx_segments: int = 80):\n",
        "    \"\"\"\n",
        "    Use GPT-4o to split transcript into segments with smart approximate timestamps.\n",
        "    \"\"\"\n",
        "    # Safety: limit extremely long texts if something goes wrong\n",
        "    full_text = full_text.strip()\n",
        "    if not full_text:\n",
        "        return []\n",
        "\n",
        "    system_msg = (\n",
        "        \"You are a precise transcript segmenter. \"\n",
        "        \"You receive a full transcript and total audio duration in seconds. \"\n",
        "        \"You must split the transcript into ordered segments with approximate start/end timestamps. \"\n",
        "        \"Timestamps must be in seconds (float), non-negative, strictly increasing, \"\n",
        "        \"and end must never exceed total_duration_sec. \"\n",
        "        \"Keep the words in original order. \"\n",
        "        \"Do not invent words. \"\n",
        "        \"Return ONLY valid JSON with structure: \"\n",
        "        \"{\\\"segments\\\": [{\\\"start\\\": float, \\\"end\\\": float, \\\"text\\\": string}, ...]}.\"\n",
        "    )\n",
        "\n",
        "    user_payload = {\n",
        "        \"total_duration_sec\": total_duration_sec,\n",
        "        \"desired_segments\": approx_segments,\n",
        "        \"transcript\": full_text,\n",
        "    }\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=SEGMENT_MODEL,\n",
        "        response_format={\"type\": \"json_object\"},\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_msg},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": json.dumps(user_payload, ensure_ascii=False),\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    content = resp.choices[0].message.content\n",
        "    data = json.loads(content)\n",
        "    segments = data.get(\"segments\", [])\n",
        "\n",
        "    # Basic cleanup and clamping\n",
        "    cleaned = []\n",
        "    last_end = 0.0\n",
        "    for seg in segments:\n",
        "        try:\n",
        "            start = float(seg.get(\"start\", 0.0))\n",
        "            end   = float(seg.get(\"end\", 0.0))\n",
        "            text  = str(seg.get(\"text\", \"\")).strip()\n",
        "        except Exception:\n",
        "            continue\n",
        "        if not text:\n",
        "            continue\n",
        "        if start < 0:\n",
        "            start = 0.0\n",
        "        if end <= start:\n",
        "            end = start + 0.5\n",
        "        if start < last_end:\n",
        "            start = last_end\n",
        "        if end > total_duration_sec:\n",
        "            end = total_duration_sec\n",
        "        cleaned.append({\"start\": start, \"end\": end, \"text\": text})\n",
        "        last_end = end\n",
        "        if last_end >= total_duration_sec:\n",
        "            break\n",
        "\n",
        "    return cleaned\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EVQNPI7DoqP"
      },
      "outputs": [],
      "source": [
        "def gpt_add_speaker_labels(segments, max_speakers: int = 4):\n",
        "    \"\"\"\n",
        "    Optional pass: ask GPT-4o to assign speaker labels (S1, S2, ...) to each segment.\n",
        "    \"\"\"\n",
        "    if not segments:\n",
        "        return segments\n",
        "\n",
        "    system_msg = (\n",
        "        \"You are a diarization assistant working ONLY from text. \"\n",
        "        \"Assign speaker labels S1, S2, ..., up to a maximum number of speakers. \"\n",
        "        \"Use consistent labels for the same voice across segments. \"\n",
        "        \"If unsure, keep the same speaker as previous segment. \"\n",
        "        \"Do not change start/end/text. \"\n",
        "        \"Return ONLY JSON: {\\\"segments\\\": [{\\\"start\\\": float, \\\"end\\\": float, \\\"text\\\": str, \\\"speaker\\\": str}, ...]}.\"\n",
        "    )\n",
        "\n",
        "    payload = {\n",
        "        \"max_speakers\": max_speakers,\n",
        "        \"segments\": segments,\n",
        "    }\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=SEGMENT_MODEL,\n",
        "        response_format={\"type\": \"json_object\"},\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_msg},\n",
        "            {\"role\": \"user\", \"content\": json.dumps(payload, ensure_ascii=False)},\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    content = resp.choices[0].message.content\n",
        "    data = json.loads(content)\n",
        "    out_segments = data.get(\"segments\", [])\n",
        "\n",
        "    # Fallback if GPT returns rubbish\n",
        "    if not out_segments:\n",
        "        return segments\n",
        "\n",
        "    cleaned = []\n",
        "    for base, new in zip(segments, out_segments):\n",
        "        speaker = str(new.get(\"speaker\", \"\")).strip() or None\n",
        "        seg = {\n",
        "            \"start\": base[\"start\"],\n",
        "            \"end\": base[\"end\"],\n",
        "            \"text\": base[\"text\"],\n",
        "        }\n",
        "        if speaker:\n",
        "            seg[\"speaker\"] = speaker\n",
        "        cleaned.append(seg)\n",
        "\n",
        "    return cleaned\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZgGjcp8DsXD"
      },
      "outputs": [],
      "source": [
        "def format_timestamp(sec: float) -> str:\n",
        "    td = timedelta(seconds=sec)\n",
        "    total_ms = int(td.total_seconds() * 1000)\n",
        "    hours = total_ms // 3_600_000\n",
        "    minutes = (total_ms % 3_600_000) // 60_000\n",
        "    seconds = (total_ms % 60_000) // 1000\n",
        "    milliseconds = total_ms % 1000\n",
        "    return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"\n",
        "\n",
        "\n",
        "def export_srt(segments, out_path: Path) -> Path:\n",
        "    \"\"\"\n",
        "    segments: list of dicts with keys: start, end, text, optional speaker.\n",
        "    \"\"\"\n",
        "    lines = []\n",
        "    for idx, seg in enumerate(segments, start=1):\n",
        "        start_ts = format_timestamp(seg[\"start\"])\n",
        "        end_ts   = format_timestamp(seg[\"end\"])\n",
        "        text     = seg[\"text\"].strip()\n",
        "        speaker  = seg.get(\"speaker\")\n",
        "\n",
        "        if speaker:\n",
        "            text = f\"{speaker}: {text}\"\n",
        "\n",
        "        lines.append(str(idx))\n",
        "        lines.append(f\"{start_ts} --> {end_ts}\")\n",
        "        lines.append(text)\n",
        "        lines.append(\"\")\n",
        "\n",
        "    out_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
        "    return out_path\n",
        "\n",
        "\n",
        "def export_txt(segments, out_path: Path) -> Path:\n",
        "    \"\"\"\n",
        "    Export plain readable transcript.\n",
        "    If speaker labels exist, include them.\n",
        "    \"\"\"\n",
        "    lines = []\n",
        "    for seg in segments:\n",
        "        text = seg[\"text\"].strip()\n",
        "        speaker = seg.get(\"speaker\")\n",
        "        if speaker:\n",
        "            lines.append(f\"{speaker}: {text}\")\n",
        "        else:\n",
        "            lines.append(text)\n",
        "    out_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
        "    return out_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPdY-lVgDvet"
      },
      "outputs": [],
      "source": [
        "def process_single_mts(mts_path: Path, language: str = None, prompt: str = None):\n",
        "    \"\"\"\n",
        "    .MTS \u2192 16k WAV \u2192 normalize \u2192 GPT-4o Transcribe \u2192 GPT-4o smart timestamps\n",
        "    \u2192 optional speaker labels \u2192 SRT + TXT.\n",
        "    \"\"\"\n",
        "    print(f\"Input: {mts_path}\")\n",
        "\n",
        "    # 1) Convert to WAV\n",
        "    wav_path = OUT_WAV_DIR / f\"{mts_path.stem}_16k_mono.wav\"\n",
        "    wav_path = mts_to_wav_16k_mono(mts_path, wav_path)\n",
        "    print(f\"WAV generated: {wav_path}\")\n",
        "\n",
        "    # 2) Normalize\n",
        "    normalize_wav(wav_path)\n",
        "    print(\"Audio normalized.\")\n",
        "\n",
        "    # 3) Duration\n",
        "    duration_sec = get_audio_duration_seconds(wav_path)\n",
        "    print(f\"Duration: {duration_sec:.1f} seconds\")\n",
        "\n",
        "    # 4) Transcription (text only)\n",
        "    try:\n",
        "        full_text = transcribe_with_gpt4o_transcribe(wav_path, language=language, prompt=prompt)\n",
        "    except Exception as e:\n",
        "        print(\"Transcription error:\", repr(e))\n",
        "        return None, None\n",
        "\n",
        "    # 5) Smart segmentation\n",
        "    try:\n",
        "        segments = gpt_smart_segments(full_text, total_duration_sec=duration_sec)\n",
        "    except Exception as e:\n",
        "        print(\"Segmentation error:\", repr(e))\n",
        "        return None, None\n",
        "\n",
        "    print(f\"Smart segments created: {len(segments)}\")\n",
        "\n",
        "    # 6) Optional speaker guessing\n",
        "    if ENABLE_SPEAKER_GUESS:\n",
        "        try:\n",
        "            segments = gpt_add_speaker_labels(segments)\n",
        "            print(\"Speaker labels added.\")\n",
        "        except Exception as e:\n",
        "            print(\"Speaker-labelling error (ignored):\", repr(e))\n",
        "\n",
        "    # 7) Export\n",
        "    srt_path = OUT_SRT_DIR / f\"{mts_path.stem}.srt\"\n",
        "    txt_path = OUT_TXT_DIR / f\"{mts_path.stem}.txt\"\n",
        "\n",
        "    export_srt(segments, srt_path)\n",
        "    export_txt(segments, txt_path)\n",
        "\n",
        "    print(\"Completed.\")\n",
        "    print(\"SRT:\", srt_path)\n",
        "    print(\"TXT:\", txt_path)\n",
        "\n",
        "    return srt_path, txt_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw0D4uHbDxrS",
        "outputId": "2702e1a6-0afb-431f-b9e3-3d7ffbc357ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files detected: 11\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00062.MTS'),\n",
              " PosixPath('/content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00063.MTS'),\n",
              " PosixPath('/content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00064.MTS'),\n",
              " PosixPath('/content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00065.MTS'),\n",
              " PosixPath('/content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00066.MTS'),\n",
              " PosixPath('/content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00067.MTS'),\n",
              " PosixPath('/content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00068.MTS'),\n",
              " PosixPath('/content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00069.MTS'),\n",
              " PosixPath('/content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00070.MTS'),\n",
              " PosixPath('/content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00071.MTS'),\n",
              " PosixPath('/content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00072.MTS')]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "mts_files = list(AUDIO_DIR.glob(\"*.MTS\")) + list(AUDIO_DIR.glob(\"*.mts\"))\n",
        "print(\"Files detected:\", len(mts_files))\n",
        "mts_files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qE5UIWTD0FA",
        "outputId": "55da0e59-8a8a-4329-8973-318828ee3fbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Processing: 00062.MTS\n",
            "Input: /content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00062.MTS\n",
            "================================================================================\n",
            "Processing: 00063.MTS\n",
            "Input: /content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00063.MTS\n",
            "================================================================================\n",
            "Processing: 00064.MTS\n",
            "Input: /content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00064.MTS\n",
            "WAV generated: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/wav_16k/00062_16k_mono.wav\n",
            "Audio normalized.\n",
            "Duration: 1.9 seconds\n",
            "Sending audio to GPT-4o Transcribe...\n",
            "WAV generated: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/wav_16k/00063_16k_mono.wav\n",
            "Audio normalized.\n",
            "Transcription finished.\n",
            "Duration: 1.9 seconds\n",
            "Sending audio to GPT-4o Transcribe...\n",
            "Smart segments created: 1\n",
            "Completed.\n",
            "SRT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/srt/00062.srt\n",
            "TXT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/txt/00062.txt\n",
            "================================================================================\n",
            "Processing: 00065.MTS\n",
            "Input: /content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00065.MTS\n",
            "Transcription finished.\n",
            "Smart segments created: 1\n",
            "Completed.\n",
            "SRT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/srt/00063.srt\n",
            "TXT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/txt/00063.txt\n",
            "================================================================================\n",
            "Processing: 00066.MTS\n",
            "Input: /content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00066.MTS\n",
            "WAV generated: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/wav_16k/00064_16k_mono.wav\n",
            "Audio normalized.\n",
            "Duration: 112.8 seconds\n",
            "Sending audio to GPT-4o Transcribe...\n",
            "Transcription finished.\n",
            "Smart segments created: 27\n",
            "Completed.\n",
            "SRT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/srt/00064.srt\n",
            "TXT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/txt/00064.txt\n",
            "================================================================================\n",
            "Processing: 00067.MTS\n",
            "Input: /content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00067.MTS\n",
            "WAV generated: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/wav_16k/00066_16k_mono.wav\n",
            "WAV generated: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/wav_16k/00065_16k_mono.wav\n",
            "Audio normalized.\n",
            "Audio normalized.\n",
            "Duration: 639.8 seconds\n",
            "Sending audio to GPT-4o Transcribe...\n",
            "Duration: 639.4 seconds\n",
            "Sending audio to GPT-4o Transcribe...\n",
            "WAV generated: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/wav_16k/00067_16k_mono.wav\n",
            "Audio normalized.\n",
            "Duration: 639.9 seconds\n",
            "Sending audio to GPT-4o Transcribe...\n",
            "Transcription finished.\n",
            "Transcription finished.\n",
            "Transcription finished.\n",
            "Smart segments created: 57\n",
            "Completed.\n",
            "SRT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/srt/00065.srt\n",
            "TXT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/txt/00065.txt\n",
            "================================================================================\n",
            "Processing: 00068.MTS\n",
            "Input: /content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00068.MTS\n",
            "Smart segments created: 65\n",
            "Completed.\n",
            "SRT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/srt/00066.srt\n",
            "TXT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/txt/00066.txt\n",
            "================================================================================\n",
            "Processing: 00069.MTS\n",
            "Input: /content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00069.MTS\n",
            "Smart segments created: 74\n",
            "Completed.\n",
            "SRT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/srt/00067.srt\n",
            "TXT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/txt/00067.txt\n",
            "================================================================================\n",
            "Processing: 00070.MTS\n",
            "Input: /content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00070.MTS\n",
            "WAV generated: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/wav_16k/00068_16k_mono.wav\n",
            "Audio normalized.\n",
            "Duration: 639.8 seconds\n",
            "Sending audio to GPT-4o Transcribe...\n",
            "WAV generated: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/wav_16k/00069_16k_mono.wav\n",
            "Audio normalized.\n",
            "Duration: 639.9 seconds\n",
            "Sending audio to GPT-4o Transcribe...\n",
            "Transcription finished.\n",
            "WAV generated: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/wav_16k/00070_16k_mono.wav\n",
            "Audio normalized.\n",
            "Duration: 639.8 seconds\n",
            "Sending audio to GPT-4o Transcribe...\n",
            "Transcription finished.\n",
            "Transcription finished.\n",
            "Smart segments created: 39\n",
            "Completed.\n",
            "SRT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/srt/00068.srt\n",
            "TXT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/txt/00068.txt\n",
            "================================================================================\n",
            "Processing: 00071.MTS\n",
            "Input: /content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00071.MTS\n",
            "Smart segments created: 51\n",
            "Completed.\n",
            "SRT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/srt/00069.srt\n",
            "TXT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/txt/00069.txt\n",
            "================================================================================\n",
            "Processing: 00072.MTS\n",
            "Input: /content/drive/Shareddrives/Analytics Team/Clients Deliverables/IPTK/IPTK VIDEO/SABAH/22-11-2025 10 AM BUMI 61+/00072.MTS\n",
            "Smart segments created: 31\n",
            "Completed.\n",
            "SRT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/srt/00070.srt\n",
            "TXT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/txt/00070.txt\n",
            "WAV generated: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/wav_16k/00072_16k_mono.wav\n",
            "Audio normalized.\n",
            "Duration: 151.2 seconds\n",
            "Sending audio to GPT-4o Transcribe...\n",
            "Transcription finished.\n",
            "Smart segments created: 44\n",
            "Completed.\n",
            "SRT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/srt/00072.srt\n",
            "TXT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/txt/00072.txt\n",
            "WAV generated: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/wav_16k/00071_16k_mono.wav\n",
            "Audio normalized.\n",
            "Duration: 639.9 seconds\n",
            "Sending audio to GPT-4o Transcribe...\n",
            "Transcription finished.\n",
            "Smart segments created: 80\n",
            "Completed.\n",
            "SRT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/srt/00071.srt\n",
            "TXT: /content/drive/MyDrive/whisdiar_gpt4o_smart_ts/txt/00071.txt\n"
          ]
        }
      ],
      "source": [
        "import concurrent.futures\n",
        "\n",
        "def worker(path: Path):\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Processing:\", path.name)\n",
        "    return process_single_mts(path, language=None)\n",
        "\n",
        "NUM_WORKERS = 3\n",
        "\n",
        "if mts_files:\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=NUM_WORKERS) as ex:\n",
        "        list(ex.map(worker, mts_files))\n",
        "else:\n",
        "    print(\"No MTS files to process.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# CORRECTION WORKFLOW\n",
        "# ==========================================\n",
        "# List of files to re-process. Use filenames only.\n",
        "FILES_TO_FIX = [\n",
        "    # \"00065.MTS\",\n",
        "    # \"00072.MTS\",\n",
        "]\n",
        "\n",
        "# Optional overrides\n",
        "FORCE_LANGUAGE = None  # e.g. \"ms\" or \"en\"\n",
        "FORCE_PROMPT   = None  # e.g. \"This is a meeting in Malay and English.\"\n",
        "\n",
        "if FILES_TO_FIX:\n",
        "    print(f\"Starting correction for {len(FILES_TO_FIX)} files...\")\n",
        "    for fname in FILES_TO_FIX:\n",
        "        # Find the full path\n",
        "        found = list(AUDIO_DIR.glob(fname))\n",
        "        if not found:\n",
        "            print(f\"File not found: {fname}\")\n",
        "            continue\n",
        "        \n",
        "        path = found[0]\n",
        "        print(f\"Re-processing: {path.name}\")\n",
        "        process_single_mts(path, language=FORCE_LANGUAGE, prompt=FORCE_PROMPT)\n",
        "else:\n",
        "    print(\"No files listed for correction.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}